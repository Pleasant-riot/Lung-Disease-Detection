{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPN ? (확실하지 않음..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _upsample_add(x, y):\n",
    "    _,_,H,W = y.size()\n",
    "    return functional.interpolate(x, size=(H,W), mode='bilinear') + y\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "def normal_init(m, mean, stddev, truncated=False):\n",
    "    # x is a parameter\n",
    "    if truncated:\n",
    "        m.weight.data.normal_().fmod_(2).mul_(stddev).add_(mean)  # not a perfect approximation\n",
    "    else:\n",
    "        m.weight.data.normal_(mean, stddev)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "def fpn(out_channels,C2,C3,C4):\n",
    "      \n",
    "#         P5 = torch.nn.MaxPool2d(kernel_size=1, stride=2, padding=0)\n",
    "        P5 = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        P4_conv1 = torch.nn.Conv2d(512, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        P4_conv2 = torch.nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "\n",
    "        P3_conv1 = torch.nn.Conv2d(512, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        P3_conv2 = torch.nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "\n",
    "        P2_conv1 = torch.nn.Conv2d(256, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        P2_conv2 = torch.nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "\n",
    "        normal_init(P4_conv1, 0, 0.01)\n",
    "        normal_init(P4_conv2, 0, 0.01)\n",
    "        normal_init(P3_conv1, 0, 0.01)\n",
    "        normal_init(P3_conv2, 0, 0.01)\n",
    "        normal_init(P2_conv1, 0, 0.01)\n",
    "        normal_init(P2_conv2, 0, 0.01)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        p4_out = P4_conv1(C4)\n",
    "\n",
    "        p5_out = P5(p4_out)\n",
    "\n",
    "        p3_out = _upsample_add(p4_out, P3_conv1(C3))\n",
    "        p2_out = _upsample_add(p3_out, P2_conv1(C2))\n",
    "\n",
    "        p4_out = P4_conv2(p4_out)\n",
    "        p3_out = P3_conv2(p3_out)\n",
    "        p2_out = P2_conv2(p2_out)\n",
    "\n",
    "        return p2_out, p3_out, p4_out, p5_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.keras.models import Sequential\n",
    "# from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "# from tensorflow.python.keras.layers.convolutional import Conv2D , MaxPooling2D\n",
    "# from tensorflow.python.keras.layers.convolutional import MaxPooling2D\n",
    "# from tensorflow.python.keras.layers import Activation , Flatten, Dropout, Dense\n",
    "# from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.python.keras.models.Sequential([\n",
    "    \n",
    "    tf.python.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(226, 226, 3)),\n",
    "    tf.python.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    tf.python.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.python.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.python.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.python.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.python.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.python.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.python.keras.layers.Flatten(),\n",
    "    tf.python.keras.layers.Dense(512, activation='relu'),\n",
    "    \n",
    "    tf.python.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 110, 110, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 53, 53, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 9,680,067\n",
      "Trainable params: 9,680,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for %: 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8afa5018fbf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#     tf.python.keras.layers.MaxPooling2D(2,2),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mfpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#     tf.python.keras.layers.Flatten(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-7d48da72e453>\u001b[0m in \u001b[0;36mfpn\u001b[0;34m(out_channels, C2, C3, C4)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mP5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaptiveAvgPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mP4_conv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mP4_conv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m    330\u001b[0m         super(Conv2d, self).__init__(\n\u001b[1;32m    331\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             False, _pair(0), groups, bias, padding_mode)\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0min_channels\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'in_channels must be divisible by groups'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out_channels must be divisible by groups'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for %: 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "C2= tf.python.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(226, 226, 3))\n",
    "C3= tf.python.keras.layers.Conv2D(64, (3,3), activation='relu')\n",
    "C4= tf.python.keras.layers.Conv2D(128, (3,3), activation='relu')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = tf.python.keras.models.Sequential([\n",
    "    \n",
    "#     tf.python.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(226, 226, 3)),\n",
    "#     tf.python.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "#     tf.python.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "#     tf.python.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "#     tf.python.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "#     tf.python.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "#     tf.python.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "#     tf.python.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    fpn((3,3),C2,C3,C4)\n",
    "    \n",
    "#     tf.python.keras.layers.Flatten(),\n",
    "#     tf.python.keras.layers.Dense(512, activation='relu'),\n",
    "    \n",
    "#     tf.python.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "#math.ceil() method rounds a number upwards to the nearest integer, and returns the result\n",
    "def spatial_pyramid_pool(self,previous_conv,num_sample,previous_conv_size,out_pool_size):\n",
    "    '''\n",
    "    previous_conv: a tensor vector of previous convolution layer\n",
    "    num_sample: an int number of image in the batch\n",
    "    previous_conv_size: an int vector [height, width] of the matrix features size of previous convolution layer\n",
    "    out_pool_size: a int vector of expected output size of max pooling layer\n",
    "    \n",
    "    returns: a tensor vector with shape [1 x n] is the concentration of multi-level pooling\n",
    "    '''    \n",
    "    #print (previous_conv_size)\n",
    "    for i in range(len(out_pool_size)):\n",
    "        h_wid=int(math.ceil(previous_conv_size[0]/out_pool_size[i]))\n",
    "        w_wid=int(math.seil(previous_conv_size[1]/out_pool_size[i]))\n",
    "        h_pad=(h_wid*out_pool_size[i]-previous_conv_size[0]+1)/2\n",
    "        w_pad=(w_wid*out_pool_size[i]-previous_conv_size[1]+1)/2\n",
    "        maxpool=nn.MaxPool2d((h_wid,w_wid),stride=(h_wid,w_wid),padding=(h_pad,w_pad))\n",
    "        x = maxpool(previous_conv)\n",
    "        if(i == 0):\n",
    "            spp = x.view(num_sample,-1)\n",
    "            # print(\"spp size:\",spp.size())\n",
    "        else:\n",
    "            # print(\"size:\",spp.size())\n",
    "            spp = torch.cat((spp,x.view(num_sample,-1)), 1)\n",
    "    return spp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "class SPP_NET(nn.Module):\n",
    "    '''\n",
    "    A CNN model which adds spp layer so that we can input multi-size tensor\n",
    "    '''\n",
    "    def __init__(self, opt, input_nc, ndf=64,  gpu_ids=[]):\n",
    "        super(SPP_NET, self).__init__()\n",
    "        self.gpu_ids = gpu_ids\n",
    "        self.output_num = [4,2,1]\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(input_nc, ndf, 4, 2, 1, bias=False)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(ndf, ndf * 2, 4, 1, 1, bias=False)\n",
    "        self.BN1 = nn.BatchNorm2d(ndf * 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, 4, 1, 1, bias=False)\n",
    "        self.BN2 = nn.BatchNorm2d(ndf * 4)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, 4, 1, 1, bias=False)\n",
    "        self.BN3 = nn.BatchNorm2d(ndf * 8)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(ndf * 8, 64, 4, 1, 0, bias=False)\n",
    "        self.fc1 = nn.Linear(10752,4096)\n",
    "        self.fc2 = nn.Linear(4096,1000)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.LReLU1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(self.BN1(x))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.leaky_relu(self.BN2(x))\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        # x = F.leaky_relu(self.BN3(x))\n",
    "        # x = self.conv5(x)\n",
    "        spp = spatial_pyramid_pool(x,1,[int(x.size(2)),int(x.size(3))],self.output_num)\n",
    "        # print(spp.size())\n",
    "        fc1 = self.fc1(spp)\n",
    "        fc2 = self.fc2(fc1)\n",
    "        s = nn.Sigmoid()\n",
    "        output = s(fc2)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    cfg = {'FPN': True, 'feature_channel_number':256, 'backbone_type':'R50'}\n",
    "    bb = FPN(cfg)\n",
    "    x = torch.randn(1, 3, 1024, 1024)\n",
    "    y = bb(x)\n",
    "    for i in y:\n",
    "        print(i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.SPP_NET"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPP_NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
