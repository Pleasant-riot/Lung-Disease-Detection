{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from imageio import imsave\n",
    "from PIL import Image\n",
    "from statistics import stdev \n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "== memory usage check\n",
      "==  0 exec\n",
      "BEFORE CODE: memory_usage_percent: 62.6%\n",
      "BEFORE CODE: Current memory KB   :    19.629 KB\n",
      "AFTER  CODE: memory_usage_percent: 64.4%\n",
      "AFTER  CODE: Current memory KB   :   368.125 KB\n",
      "------------------------------------------------------------\n",
      "==  1 exec\n",
      "BEFORE CODE: memory_usage_percent: 62.7%\n",
      "BEFORE CODE: Current memory KB   :    21.020 KB\n",
      "AFTER  CODE: memory_usage_percent: 64.4%\n",
      "AFTER  CODE: Current memory KB   :   368.199 KB\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#메모리확인\n",
    "\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "print(\"==\"*20)\n",
    "print(\"== memory usage check\")\n",
    "\n",
    "for exec_num in range(0, 2):\n",
    "    # BEFORE code\n",
    "    print(f\"== {exec_num:2d} exec\")\n",
    "    # general RAM usage\n",
    "    memory_usage_dict = dict(psutil.virtual_memory()._asdict())\n",
    "    memory_usage_percent = memory_usage_dict['percent']\n",
    "    print(f\"BEFORE CODE: memory_usage_percent: {memory_usage_percent}%\")\n",
    "    # current process RAM usage\n",
    "    pid = os.getpid()\n",
    "    current_process = psutil.Process(pid)\n",
    "    current_process_memory_usage_as_KB = current_process.memory_info()[0] / 2.**20\n",
    "    print(f\"BEFORE CODE: Current memory KB   : {current_process_memory_usage_as_KB: 9.3f} KB\")\n",
    "\n",
    "    X = [i for i in range(0, 9000000)]\n",
    "    # AFTER  code\n",
    "    memory_usage_dict = dict(psutil.virtual_memory()._asdict())\n",
    "    memory_usage_percent = memory_usage_dict['percent']\n",
    "    print(f\"AFTER  CODE: memory_usage_percent: {memory_usage_percent}%\")\n",
    "    # current process RAM usage\n",
    "    pid = os.getpid()\n",
    "    current_process = psutil.Process(pid)\n",
    "    current_process_memory_usage_as_KB = current_process.memory_info()[0] / 2.**20\n",
    "    print(f\"AFTER  CODE: Current memory KB   : {current_process_memory_usage_as_KB: 9.3f} KB\")\n",
    "    del X\n",
    "    print(\"--\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/home/ncp/workspace/data/dataset_.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>report</th>\n",
       "      <th>pneumonia_type</th>\n",
       "      <th>orginal_dcm_file</th>\n",
       "      <th>orginal_png_file</th>\n",
       "      <th>crop_file</th>\n",
       "      <th>body_part_file</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H05_00019_02</td>\n",
       "      <td>M</td>\n",
       "      <td>A1</td>\n",
       "      <td>0개월</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>/home/ncp/workspace/data/crop/d4/H05_00019_02.png</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H01_00716_01</td>\n",
       "      <td>F</td>\n",
       "      <td>A1</td>\n",
       "      <td>0개월</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>/home/ncp/workspace/data/crop/d4/H01_00716_01.png</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H03_00172_01</td>\n",
       "      <td>F</td>\n",
       "      <td>A1</td>\n",
       "      <td>0개월</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>/home/ncp/workspace/data/crop/d4/H03_00172_01.png</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H05_00204_01</td>\n",
       "      <td>M</td>\n",
       "      <td>A1</td>\n",
       "      <td>0개월</td>\n",
       "      <td>50.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>/home/ncp/workspace/data/crop/d4/H05_00204_01.png</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H04_00178_01</td>\n",
       "      <td>F</td>\n",
       "      <td>A1</td>\n",
       "      <td>0개월</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Diffuse hazziness in both lungs. ETT insertion...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>/home/ncp/workspace/data/crop/d4/H04_00178_01.png</td>\n",
       "      <td>/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     identifier sex age_group  age  height  weight  \\\n",
       "0  H05_00019_02   M        A1  0개월     NaN     0.9   \n",
       "1  H01_00716_01   F        A1  0개월    52.0     3.9   \n",
       "2  H03_00172_01   F        A1  0개월    42.0     1.8   \n",
       "3  H05_00204_01   M        A1  0개월    50.5     3.0   \n",
       "4  H04_00178_01   F        A1  0개월    30.0     0.5   \n",
       "\n",
       "                                              report  pneumonia_type  \\\n",
       "0                                                NaN             NaN   \n",
       "1                                                NaN             NaN   \n",
       "2                                                NaN             NaN   \n",
       "3                                                NaN             NaN   \n",
       "4  Diffuse hazziness in both lungs. ETT insertion...             NaN   \n",
       "\n",
       "                                    orginal_dcm_file  \\\n",
       "0  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...   \n",
       "1  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...   \n",
       "2  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...   \n",
       "3  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...   \n",
       "4  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...   \n",
       "\n",
       "                                    orginal_png_file  \\\n",
       "0  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...   \n",
       "1  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...   \n",
       "2  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...   \n",
       "3  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...   \n",
       "4  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...   \n",
       "\n",
       "                                           crop_file  \\\n",
       "0  /home/ncp/workspace/data/crop/d4/H05_00019_02.png   \n",
       "1  /home/ncp/workspace/data/crop/d4/H01_00716_01.png   \n",
       "2  /home/ncp/workspace/data/crop/d4/H03_00172_01.png   \n",
       "3  /home/ncp/workspace/data/crop/d4/H05_00204_01.png   \n",
       "4  /home/ncp/workspace/data/crop/d4/H04_00178_01.png   \n",
       "\n",
       "                                      body_part_file  diagnosis  \n",
       "0  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...          4  \n",
       "1  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...          4  \n",
       "2  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...          4  \n",
       "3  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...          4  \n",
       "4  /home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A...          4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['identifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_list2 = []\n",
    "\n",
    "for i in del_list:\n",
    "    del_list2.append(i.replace('.png',''))\n",
    "\n",
    "def find_iden(x):\n",
    "    if x in del_list2:\n",
    "        return 'Y'\n",
    "    else:\n",
    "        return 'N'\n",
    "\n",
    "data['del?'] = data['identifier'].apply(find_iden)\n",
    "data2 = data[data['del?']=='N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = list(data['orginal_png_file'])\n",
    "mask_list = list(data['body_part_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def resize_img(img, size):\n",
    "    out_img = cv2.resize(cv2.imread(img),size)\n",
    "    return out_img\n",
    "\n",
    "def resize_img_one(img, size):\n",
    "    out_img = cv2.resize(cv2.imread(img,0),size)\n",
    "    out_img = np.reshape(out_img, (128,128,1))\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_img_one(mask_list[0],(128,128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG = np.ndarray((4000,128,128,1))\n",
    "MASK = np.ndarray((4000,128,128,3))\n",
    "\n",
    "for i in range(len(img_list)):\n",
    "    IMG[i][:][:][:] = resize_img_one(img_list[i],(128,128))\n",
    "    MASK[i][:][:][:] = resize_img(mask_list[i],(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtr, Xtst, Ytr, Ytst = train_test_split(IMG, MASK, test_size=0.10)\n",
    "Xtr, Xva, Ytr, Yva = train_test_split(IMG, MASK, test_size=0.10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, Activation, Conv2D, Dropout,MaxPooling2D,UpSampling2D, Input, ELU, Concatenate, BatchNormalization\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "# Model code\n",
    "\n",
    "first_input = Input(shape =(128,128,1))\n",
    "bn = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(first_input)\n",
    "conv1_1 = Conv2D(128, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(bn)\n",
    "conv1_2=Conv2D(128, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(conv1_1)\n",
    "dropout1 = Dropout(0.1)(conv1_2)\n",
    "maxPool1 = MaxPooling2D(pool_size=2, strides=1)(dropout1)\n",
    "conv2_1 = Conv2D(64, [3,3], strides=(2, 2), activation='elu', padding=\"same\")(maxPool1)\n",
    "conv2_2 = Conv2D(64, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(conv2_1)\n",
    "dropout2 = Dropout(0.1)(conv2_2)\n",
    "maxPool2 = MaxPooling2D(pool_size=2, strides=1)(dropout2)\n",
    "conv3_1 = Conv2D(32, [3,3], strides=(2, 2), activation='elu', padding=\"same\")(maxPool2)\n",
    "conv3_2 = Conv2D(32, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(conv3_1)\n",
    "dropout3 = Dropout(0.1)(conv3_2)\n",
    "maxPool3 = MaxPooling2D(pool_size=2, strides=1)(dropout3)\n",
    "\n",
    "conv4_1 = Conv2D(16, [3,3], strides=(2, 2), activation='elu', padding=\"same\")(maxPool3)\n",
    "conv4_2 = Conv2D(16, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(conv4_1)\n",
    "dropout4 = Dropout(0.1)(conv4_2)\n",
    "\n",
    "upSampling1 = UpSampling2D(size=(2, 2))(dropout4)\n",
    "\n",
    "#concatenate\n",
    "conv_int5 = Conv2D(32, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(upSampling1)\n",
    "concat1 = Concatenate()([dropout3, conv_int5])\n",
    "\n",
    "conv5_1 = Conv2D(32, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(concat1)\n",
    "conv5_2 = Conv2D(32, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(conv5_1)\n",
    "dropout5 = Dropout(0.1)(conv5_2)\n",
    "upSampling2 = UpSampling2D(size=(2, 2))(dropout5)\n",
    "#concatenate\n",
    "conv_int6 = Conv2D(64, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(upSampling2)\n",
    "concat2 = Concatenate()([dropout2, conv_int6])\n",
    "\n",
    "conv6_1 = Conv2D(64, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(concat2)\n",
    "conv6_2 = Conv2D(64, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(conv6_1)\n",
    "dropout6 = Dropout(0.1)(conv6_2)\n",
    "upSampling3 = UpSampling2D(size=(2, 2))(dropout6)\n",
    "\n",
    "#concatenate\n",
    "conv_int7 = Conv2D(128, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(upSampling3)\n",
    "concat3 = Concatenate()([dropout1, conv_int7])\n",
    "\n",
    "conv7_1 = Conv2D(128, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(concat3)\n",
    "conv7_2 = Conv2D(128, [3,3], strides=(1, 1), activation='elu', padding=\"same\")(conv7_1)\n",
    "\n",
    "dropout7 = Dropout(0.1)(conv7_2)\n",
    "\n",
    "#batch normalization\n",
    "bn = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(dropout7)\n",
    "\n",
    "# output = Conv2D(4, [1,1], strides=(1, 1), activation='softmax', padding=\"same\")(bn)\n",
    "output2 = Conv2D(3, [1,1], strides=(1, 1), activation='softmax', padding=\"same\")(bn)\n",
    "\n",
    "model = Model(inputs=first_input, outputs=output2)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 128, 128, 1)  4           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 128 1280        batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 128, 128 147584      conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128, 128, 128 0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 127, 127, 128 0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 64, 64, 64)   73792       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64, 64, 64)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 63, 63, 64)   0           dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 32)   18464       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 32)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 31, 31, 32)   0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 16)   4624        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 16)   2320        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 16)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 16)   0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 32)   4640        up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 64)   0           dropout_16[0][0]                 \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 32, 32)   18464       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32, 32, 32)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 64, 64, 32)   0           dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 64, 64, 64)   18496       up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 128)  0           dropout_15[0][0]                 \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 64, 64, 64)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 128, 128, 64) 0           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 128, 128, 128 73856       up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128, 128, 256 0           dropout_14[0][0]                 \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 128, 128, 128 295040      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 128, 128, 128 147584      conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 128, 128, 128 0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 128, 128, 128 512         dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 128, 128, 3)  387         batch_normalization_v1_5[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 973,191\n",
      "Trainable params: 972,933\n",
      "Non-trainable params: 258\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3240 samples, validate on 360 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Error while reading resource variable batch_normalization_v1_5/gamma from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/batch_normalization_v1_5/gamma/N10tensorflow3VarE does not exist.\n\t [[{{node batch_normalization_v1_5/cond/ReadVariableOp}}]]\n\t [[{{node loss_2/mul}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-917715cdd90e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable batch_normalization_v1_5/gamma from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/batch_normalization_v1_5/gamma/N10tensorflow3VarE does not exist.\n\t [[{{node batch_normalization_v1_5/cond/ReadVariableOp}}]]\n\t [[{{node loss_2/mul}}]]"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_test.h5', verbose=1, save_best_only = True)\n",
    "\n",
    "# callbacks = [\n",
    "#              tf.keras.callbacks.EarlyStopping(patience=2, monitor='accuracy'),\n",
    "#              tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "# ]\n",
    "\n",
    "results = model.fit(Xtr,Ytr, validation_split=0.1, batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
