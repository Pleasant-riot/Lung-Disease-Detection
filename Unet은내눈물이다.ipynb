{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet은내눈물이다.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1z7on6GeLVnf11FQ-h9P1y70CeYNLOJj5",
      "authorship_tag": "ABX9TyPH1mtMsk5cwZxT7VqMSN6n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kikiru328/Pneumonia-Detection/blob/main/Unet%EC%9D%80%EB%82%B4%EB%88%88%EB%AC%BC%EC%9D%B4%EB%8B%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3uUqElaggWj"
      },
      "source": [
        "# Model U-net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0R7IQ36gnBE"
      },
      "source": [
        "###### import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjY3dH3Hggen"
      },
      "source": [
        "# Basic\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Deeplearning model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_q4NGIFgxfD"
      },
      "source": [
        "###### setting hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIkVyrbzl_0h",
        "outputId": "927be047-1c13-41b3-809b-03cedabbc2e7"
      },
      "source": [
        "cd /content/drive/MyDrive/UnetTest"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/UnetTest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q0MjedFjrEv"
      },
      "source": [
        "lr = 1e-3\n",
        "batch_size = 4\n",
        "num_epoch = 100\n",
        "\n",
        "# 학습할 데이터가 저장된 경로\n",
        "data_dir = '/content/drive/MyDrive/UnetTest'\n",
        "\n",
        "# 학습된 데이터가 저장될 경로\n",
        "ckpt_dir = './checkpoint'\n",
        "\n",
        "# 텐서보드 로그파일 저장될 경로\n",
        "log_dir = './log'\n",
        "\n",
        "# gpu / cpu 어떤걸 쓸지 device 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcidrFy5mut9"
      },
      "source": [
        "# Unet Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4uaFllumw4x"
      },
      "source": [
        "# nn.Module 을 Unet 클래스에 상속시킴\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "        # U-net 첫번째 단계 파란색 화살표 convolution 에 대한 정의\n",
        "        def CBR2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True): # 총 6개의 argument로 구성된 2D function  적용\n",
        "            layers = []\n",
        "            \n",
        "            # Convolution layer 정의\n",
        "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)]\n",
        "\n",
        "            # batch normalize layer 정의\n",
        "            layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
        "\n",
        "            # Relu layer 정의\n",
        "            layers += [nn.ReLU()]\n",
        "\n",
        "            cbr = nn.Sequential(*layers)\n",
        "\n",
        "            return cbr\n",
        "\n",
        "        # 해당 initial 함수에서는 해당 Unet을 정의하는데 있어 필요한 레이어들을 선언을 함.\n",
        "        # forward는 init 함수에서 생성한 레이어들을 연결하는 함수.\n",
        "        \n",
        "\n",
        "        # 첫번째 파란색 화살표. 첫번째 Encoder (Enc) , stage 1 , first CBR\n",
        "        # Contracting path\n",
        "        # kernel_size, stride, padding, bias 는 CBR layer에서는 고정. --> Predifined이 되어있음. 따라서 in_channels ,out_channels만 사용하게됨.\n",
        "        # self.enc1_1 = CBR2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.enc1_1 = CBR2d(in_channels=1, out_channels=64)\n",
        "        self.enc1_2 = CBR2d(in_channels=64, out_channels=64)\n",
        "       \n",
        "\n",
        "        # 두번째 빨간색 화살표 , Maxpooling part (2x2)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # 두번째 파란색 화살표. layers\n",
        "        self.enc2_1 = CBR2d(in_channels=64, out_channels=128)\n",
        "        self.enc2_2 = CBR2d(in_channels=64, out_channels=128)\n",
        "\n",
        "        # 다음 빨간색 화살표 maxpooling part (2x2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # 세번째 파란색 화살표 layers\n",
        "        self.enc3_1 = CBR2d(in_channels=128, out_channels=256)\n",
        "        self.enc3_2 = CBR2d(in_channels=256, out_channels=256)\n",
        "\n",
        "        # 다음 빨간색 화살표  maxpooling part (2x2)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # 네번째 파란색 화살표 layers\n",
        "        self.enc4_1 = CBR2d(in_channels=256, out_channels=512)  \n",
        "        self.enc4_2 = CBR2d(in_channels=512, out_channels=512)\n",
        "\n",
        "        # 다음 빨간색 화살표 maxpooling part (2x2)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
        "        \n",
        "        # Encoder part의 마지막 CBR layer\n",
        "        self.enc5_1 = CBR2d(in_channels=512, out_channels=1024)\n",
        "\n",
        "        # Decoder part\n",
        "        self.dec5_1 = CBR2d(in_channels=1024, out_channels=512)\n",
        "\n",
        "        # 다음 초록색 화살표 upconvolution network (2x2) - unpooling\n",
        "        # maxpool stage(4) 와 동일하게 unpool stage(4)\n",
        "        self.unpool4 = nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=2, stride=2, padding=0, bias=True)\n",
        "\n",
        "        # CBR decode part\n",
        "        # Encoder part 의 index 와 Decoder part의 index를 동일하게 잡아주기 위함\n",
        "        # Decoder의 input_channels 와 output_channels 는 Encoder의 input_channels와 output_channels 의 정반대의 값을 보임 (거울, U)\n",
        "        # Encoder part에서 하나가 추가되어 2배가 됨 ( in_channel)\n",
        "        # 따라서 Decoder part의 첫번째 시작하는 입력의 채널 사이즈는 2배가 되어 진행이 되어야됨.\n",
        "        self.dec4_2 = CBR2d(in_channels=2 * 512, out_channels=512) \n",
        "        self.dec4_1 = CBR2d(in_channels=512, out_channels=256)\n",
        "\n",
        "        # 다음 초록색 화살표 upconvolution network (2x2)\n",
        "        self.unpool3 = nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=2, stride=2, padding=0, bias=True)\n",
        "\n",
        "        # Decoder stage 3\n",
        "        self.dec3_2 = CBR2d(in_channels=2 * 256, out_channels=256)\n",
        "        self.dec3_1 = CBR2d(in_channels=256, out_channels=128)\n",
        "\n",
        "        # 다음 초록색 화살표 upconvolution network (2x2)\n",
        "        self.unpool2 = nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=2, stride=2, padding=0, bias=True)\n",
        "\n",
        "        # Decoder stage 2\n",
        "        self.dec2_2 = CBR2d(in_channels=2 * 128, out_channels=128)\n",
        "        self.dec2_1 = CBR2d(in_channels=128, out_channels=64)\n",
        "\n",
        "        # 다음 초록색 화살표 upconvolution network (2x2)\n",
        "        self.unpool1 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=2, stride=2, padding=0, bias=True)\n",
        "\n",
        "        # Decoder stage 1\n",
        "        self.dec1_2 = CBR2d(in_channels=2 * 64, out_channels=64)\n",
        "        self.dec1_1 = CBR2d(in_channels=64, out_channels=64)\n",
        "\n",
        "        # 마지막으로 segmentation에 필요한 n개의 class에 대한 output을 만들기 위해 초록색 화살표 (1x1) convolution layer를 추가함.\n",
        "        # fc = Final convolution\n",
        "        self.fc = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "\n",
        "        # 각각의 layer들을 연결하는 함수 설정\n",
        "        # x = input_image\n",
        "    def forward(self, x): \n",
        "        enc1_1 = self.enc1_1(x)\n",
        "        enc1_2 = self.enc1_2(enc1_1)\n",
        "        pool1 = self.pool1(enc1_2)\n",
        "\n",
        "        enc2_1 = self.enc2_1(pool1)\n",
        "        enc2_2 = self.enc2_2(enc2_1)\n",
        "        pool2 = self.pool2(enc2_2)\n",
        "\n",
        "        enc3_1 = self.enc3_1(pool2)\n",
        "        enc3_2 = self.enc3_2(enc3_1)\n",
        "        pool3 = self.pool3(enc3_2)\n",
        "\n",
        "        enc4_1 = self.enc4_1(pool3)\n",
        "        enc4_2 = self.enc4_2(enc4_1)\n",
        "        pool4 = self.pool4(enc4_2)\n",
        "\n",
        "        enc5_1 = self.enc5_1(pool4)\n",
        "\n",
        "\n",
        "        #middle\n",
        "        dec5_1 = self.dec5_1(enc5_1)\n",
        "\n",
        "        unpool4 = self.unpool3(dec5_1)\n",
        "        # 흰색부분 연결\n",
        "        # dim = [0 : batch 방향, 1 : channel 방향, 2 : y방향(height), 3: x 방향(width)]\n",
        "        cat4 = torch.cat((unpool4, enc4_2), dim=1))\n",
        "        dec4_2 = self.dec4_2(cat4)\n",
        "        dec4_1 = self.dec4_1(dec4_2)\n",
        "\n",
        "        unpool3 = self.unpool3(dec4_1)\n",
        "        cat3 = torch.cat((unpool3, enc3_2),dim=1)\n",
        "        dec3_2 = self.dec3_2(cat3)\n",
        "        dec3_1 = self.dec3_1(dec3_2)\n",
        "\n",
        "        unpool2 = self.unpool2(dec3_1)\n",
        "        cat2 = torch.cat((unpool2, enc2_2),dim=1)\n",
        "        dec2_2 = self.dec2_2(cat2)\n",
        "        dec2_1 = self.dec2_1(dec2_2)\n",
        "\n",
        "        unpool1 = self.unpool1(dec2_1)\n",
        "        cat1 = torch.cat((unpool1,enc_1_2),dim=1)\n",
        "        dec1_2 = self.dec1_2(cat1)\n",
        "        dec1_1 = self.dec1_1(dec1_2)\n",
        "\n",
        "        x = self.fc(dec1_1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyWlS6d5wDHV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34L7K4Xlp3B6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}