{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # basic module\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import os\n",
    "# import shutil\n",
    "# import glob\n",
    "# import time\n",
    "# import pickle\n",
    "\n",
    "# plt.style.use('seaborn-dark')\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "# pd.options.display.max_rows = 20\n",
    "# pd.options.display.max_columns = 20\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = (14,4)\n",
    "# plt.rcParams['lines.linewidth'] = 2\n",
    "# plt.rcParams['lines.color'] = 'r'\n",
    "# plt.rcParams['axes.grid'] = False\n",
    "\n",
    "\n",
    "# # image module\n",
    "# import cv2\n",
    "# from pydicom import dcmread\n",
    "# import pylibjpeg\n",
    "# from PIL import Image\n",
    "# import pydicom as dcm\n",
    "# from pydicom import dcmread\n",
    "# from pydicom.data import get_testdata_file\n",
    "\n",
    "\n",
    "\n",
    "# # dataset\n",
    "# # # df = pd.read_csv('dataset.csv',index_col=0)\n",
    "\n",
    "# # # image_path\n",
    "# # d1p = '/home/ncp/workspace/data/DL/d1/'\n",
    "# # d1 = os.listdir(d1p)\n",
    "# # d1.sort()\n",
    "\n",
    "# # d2p = '/home/ncp/workspace/data/DL/d2/'\n",
    "# # d2 = os.listdir(d2p)\n",
    "# # d2.sort()\n",
    "\n",
    "# # d3p = '/home/ncp/workspace/data/DL/d3/'\n",
    "# # d3 = os.listdir(d3p)\n",
    "# # d3.sort()\n",
    "\n",
    "# # d4p = '/home/ncp/workspace/data/DL/d4/'\n",
    "# # d4 = os.listdir(d4p)\n",
    "# # d4.sort()\n",
    "\n",
    "# # d5p = '/home/ncp/workspace/data/DL/d5/'\n",
    "# # d5 = os.listdir(d5p)\n",
    "# # d5.sort()\n",
    "\n",
    "# # d6p = '/home/ncp/workspace/data/DL/d6/'\n",
    "# # d6 = os.listdir(d6p)\n",
    "# # d6.sort()\n",
    "\n",
    "# # d9p = '/home/ncp/workspace/data/DL/d9/'\n",
    "# # d9 = os.listdir(d9p)\n",
    "# # d9.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import utils\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "device = torch.device('cpu')\n",
    "# import gc\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open('/home/ncp/workspace/data/train/04.신생아호흡곤란증후군/A1.0-2개월/H05_00019_02/org/H05_00019_02.png')\n",
    "transf = Compose([Resize((384, 384)), ToTensor(),Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ])\n",
    "dataset = torchvision.datasets.ImageFolder(root='/home/ncp/workspace/data/DL',transform=transf)\n",
    "# dataset = torchvision.datasets.ImageFolder(root='/home/ncp/workspace/data/DL')\n",
    "# dataset = transf(dataset).unsqueeze(0)\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset,[3000,800,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 384, 384])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd9']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_set,batch_size=64,shuffle = True,num_workers = 4)\n",
    "val_dl = DataLoader(val_set,batch_size=64,shuffle = True,num_workers = 4)\n",
    "test_dl = DataLoader(test_set,batch_size=64,shuffle = True,num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show(img, y=None):\n",
    "#     npimg = img.numpy()\n",
    "#     npimg_tr = np.transpose(npimg, (1, 2, 0))\n",
    "#     plt.imshow(npimg_tr)\n",
    "\n",
    "#     if y is not None:\n",
    "#         plt.title('labels:' + str(y))\n",
    "\n",
    "# np.random.seed()\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "# grid_size=4\n",
    "# rnd_ind = np.random.randint(0, len(train_set), grid_size)\n",
    "\n",
    "# x_grid = [train_set[i][0] for i in rnd_ind]\n",
    "# y_grid = [val_set[i][1] for i in rnd_ind]\n",
    "\n",
    "# x_grid = utils.make_grid(x_grid, nrow=grid_size, padding=2)\n",
    "# plt.figure(figsize=(10,10))\n",
    "# show(x_grid, y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imshow(img):\n",
    "#     img = img /2 + 0.5\n",
    "#     np_img = img.numpy()\n",
    "#     plt.imshow(np.transpose(np_img, (1,2,0)))\n",
    "#     print(np_img.shape)\n",
    "#     print((np.transpose(np_img, (1,2,0))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(images.shape)\n",
    "# imshow(torchvision.utils.make_grid(images,nrow=4))\n",
    "# print(images.shape)\n",
    "# print((torchvision.utils.make_grid(images)).shape)\n",
    "# print(\"\".join(\"%5s \" % classes[labels[j]] for j in range(16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PatchEmbedding(nn.Module):\n",
    "#     def __init__(self, in_channels: int = 4, patch_size: int = 16, emb_size: int = 768):\n",
    "#         self.patch_size = patch_size\n",
    "#         super().__init__()\n",
    "#         self.projection = nn.Sequential(\n",
    "#             # using a conv layer instead of a linear one -> performance gains\n",
    "#             nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
    "#             Rearrange('b e (h) (w) -> b (h w) e'),\n",
    "#         )\n",
    "        \n",
    "#         self.cls_token = nn.Parameter(torch.randn(1,1, emb_size))\n",
    "        \n",
    "#     def forward(self, x: Tensor) -> Tensor:\n",
    "#         b, _, _, _ = x.shape\n",
    "#         x = self.projection(x)\n",
    "#         cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
    "#         # prepend the cls token to the input\n",
    "#         x = torch.cat([cls_tokens, x], dim=1)\n",
    "#         return x\n",
    "    \n",
    "# PatchEmbedding()(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels: int = 3, patch_size: int = 16, emb_size: int = 768, img_size: int = 224):\n",
    "        self.patch_size = patch_size\n",
    "        super().__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            # using a conv layer instead of a linear one -> performance gains\n",
    "            nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
    "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
    "        )\n",
    "        self.cls_token = nn.Parameter(torch.randn(1,1, emb_size))\n",
    "        self.positions = nn.Parameter(torch.randn((img_size // patch_size) **2 + 1, emb_size))\n",
    "\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        b, _, _, _ = x.shape\n",
    "        x = self.projection(x)\n",
    "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
    "        # prepend the cls token to the input\n",
    "        x = torch.cat([cls_tokens, x], dim=1)\n",
    "        # add position embedding\n",
    "        x += self.positions\n",
    "        return x\n",
    "    \n",
    "# PatchEmbedding()(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch, 1+num of patches, emb_size] =  torch.Size([16, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "# Check PatchEmbedding\n",
    "x = torch.randn(16, 3, 224, 224).to(device)\n",
    "patch_embedding = PatchEmbedding().to(device)\n",
    "patch_output = patch_embedding(x)\n",
    "print('[batch, 1+num of patches, emb_size] = ', patch_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_size=768, num_heads=8, dropout=0):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.num_heads = num_heads\n",
    "        self.keys = nn.Linear(emb_size, emb_size)\n",
    "        self.queries = nn.Linear(emb_size, emb_size)\n",
    "        self.values = nn.Linear(emb_size, emb_size)\n",
    "        self.att_drop = nn.Dropout(dropout)\n",
    "        self.projection = nn.Linear(emb_size, emb_size)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # split keys, queries and values in num_heads\n",
    "        queries = rearrange(self.queries(x), 'b n (h d) -> b h n d', h=self.num_heads) # b, 197, 728 -> b, 8, 197, 91\n",
    "        keys = rearrange(self.keys(x), 'b n (h d) -> b h n d', h=self.num_heads)\n",
    "        values = rearrange(self.values(x), 'b n (h d) -> b h n d', h=self.num_heads)\n",
    "        # sum up over the last axis, b,h,197,197\n",
    "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) # batch, num_head, query_len, key_len\n",
    "        \n",
    "        if mask is not None:\n",
    "            fill_value = torch.finfo(torch.float32).min\n",
    "            energy.mask_fill(~mask, fill_value)\n",
    "        \n",
    "        scaling = self.emb_size ** (1/2)\n",
    "        att = F.softmax(energy, dim=-1) / scaling\n",
    "        att = self.att_drop(att)\n",
    "        # sum up over the third axis\n",
    "        out = torch.einsum('bhal, bhlv -> bhav', att, values) # 197x91\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out = self.projection(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiHeadAttention(nn.Module):\n",
    "#     def __init__(self, emb_size: int = 768, num_heads: int = 8, dropout: float = 0):\n",
    "#         super().__init__()\n",
    "#         self.emb_size = emb_size\n",
    "#         self.num_heads = num_heads\n",
    "#         # fuse the queries, keys and values in one matrix\n",
    "#         self.qkv = nn.Linear(emb_size, emb_size * 3)\n",
    "#         self.att_drop = nn.Dropout(dropout)\n",
    "#         self.projection = nn.Linear(emb_size, emb_size)\n",
    "        \n",
    "#     def forward(self, x : Tensor, mask: Tensor = None) -> Tensor:\n",
    "#         # split keys, queries and values in num_heads\n",
    "#         qkv = rearrange(self.qkv(x), \"b n (h d qkv) -> (qkv) b h n d\", h=self.num_heads, qkv=3)\n",
    "#         queries, keys, values = qkv[0], qkv[1], qkv[2]\n",
    "#         # sum up over the last axis\n",
    "#         energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) # batch, num_heads, query_len, key_len\n",
    "#         if mask is not None:\n",
    "#             fill_value = torch.finfo(torch.float32).min\n",
    "#             energy.mask_fill(~mask, fill_value)\n",
    "            \n",
    "#         scaling = self.emb_size ** (1/2)\n",
    "#         att = F.softmax(energy, dim=-1) / scaling\n",
    "#         att = self.att_drop(att)\n",
    "#         # sum up over the third axis\n",
    "#         out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
    "#         out = rearrange(out, \"b h n d -> b n (h d)\")\n",
    "#         out = self.projection(out)\n",
    "#         return out\n",
    "    \n",
    "# patches_embedded = PatchEmbedding()(x)\n",
    "# MultiHeadAttention()(patches_embedded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "MHA = MultiHeadAttention()\n",
    "MHA_output = MHA(patch_output)\n",
    "print(MHA_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualAdd(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        \n",
    "    def forward(self, x, **kwargs):\n",
    "        res = x\n",
    "        x = self.fn(x, **kwargs)\n",
    "        x += res\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Sequential):\n",
    "    def __init__(self, emb_size: int, expansion: int = 4, drop_p: float = 0.):\n",
    "        super().__init__(\n",
    "            nn.Linear(emb_size, expansion * emb_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop_p),\n",
    "            nn.Linear(expansion * emb_size, emb_size),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(16,1,128).to(device)\n",
    "model = FeedForwardBlock(128).to(device)\n",
    "output = model(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(nn.Sequential):\n",
    "    def __init__(self,\n",
    "                 emb_size: int = 768,\n",
    "                 drop_p: float = 0.,\n",
    "                 forward_expansion: int = 4,\n",
    "                 forward_drop_p: float = 0.,\n",
    "                 ** kwargs):\n",
    "        super().__init__(\n",
    "            ResidualAdd(nn.Sequential(\n",
    "                nn.LayerNorm(emb_size),\n",
    "                MultiHeadAttention(emb_size, **kwargs),\n",
    "                nn.Dropout(drop_p)\n",
    "            )),\n",
    "            ResidualAdd(nn.Sequential(\n",
    "                nn.LayerNorm(emb_size),\n",
    "                FeedForwardBlock(\n",
    "                    emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
    "                nn.Dropout(drop_p)\n",
    "            )\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "# Check TransformerEncoderBlock\n",
    "model = TransformerEncoderBlock().to(device)\n",
    "output = model(patch_output).to(device)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Sequential):\n",
    "    def __init__(self, depth: int = 12, **kwargs):\n",
    "        super().__init__(*[TransformerEncoderBlock(**kwargs) for _ in range(depth)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "model = TransformerEncoder().to(device)\n",
    "output = model(patch_output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Sequential):\n",
    "    def __init__(self, emb_size: int = 768, n_classes: int = 1000):\n",
    "        super().__init__(\n",
    "            Reduce('b n e -> b e', reduction='mean'),\n",
    "            nn.LayerNorm(emb_size), \n",
    "            nn.Linear(emb_size, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1000])\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "x = torch.randn(16, 1, 768).to(device)\n",
    "model = ClassificationHead().to(device)\n",
    "output = model(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Sequential):\n",
    "    def __init__(self,     \n",
    "                in_channels: int = 3,\n",
    "                patch_size: int = 16,\n",
    "                emb_size: int = 768,\n",
    "                img_size: int = 224,\n",
    "                depth: int = 12,\n",
    "                n_classes: int = 1000,\n",
    "                **kwargs):\n",
    "        super().__init__(\n",
    "            PatchEmbedding(in_channels, patch_size, emb_size, img_size),\n",
    "            TransformerEncoder(depth, emb_size=emb_size, **kwargs),\n",
    "            ClassificationHead(emb_size, n_classes)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(16,3,224,224).to(device)\n",
    "# model = ViT().to(device)\n",
    "# output = model(x)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
      "         Rearrange-2             [-1, 196, 768]               0\n",
      "    PatchEmbedding-3             [-1, 197, 768]               0\n",
      "         LayerNorm-4             [-1, 197, 768]           1,536\n",
      "            Linear-5             [-1, 197, 768]         590,592\n",
      "            Linear-6             [-1, 197, 768]         590,592\n",
      "            Linear-7             [-1, 197, 768]         590,592\n",
      "           Dropout-8          [-1, 8, 197, 197]               0\n",
      "            Linear-9             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-10             [-1, 197, 768]               0\n",
      "          Dropout-11             [-1, 197, 768]               0\n",
      "      ResidualAdd-12             [-1, 197, 768]               0\n",
      "        LayerNorm-13             [-1, 197, 768]           1,536\n",
      "           Linear-14            [-1, 197, 3072]       2,362,368\n",
      "             GELU-15            [-1, 197, 3072]               0\n",
      "          Dropout-16            [-1, 197, 3072]               0\n",
      "           Linear-17             [-1, 197, 768]       2,360,064\n",
      "          Dropout-18             [-1, 197, 768]               0\n",
      "      ResidualAdd-19             [-1, 197, 768]               0\n",
      "        LayerNorm-20             [-1, 197, 768]           1,536\n",
      "           Linear-21             [-1, 197, 768]         590,592\n",
      "           Linear-22             [-1, 197, 768]         590,592\n",
      "           Linear-23             [-1, 197, 768]         590,592\n",
      "          Dropout-24          [-1, 8, 197, 197]               0\n",
      "           Linear-25             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-26             [-1, 197, 768]               0\n",
      "          Dropout-27             [-1, 197, 768]               0\n",
      "      ResidualAdd-28             [-1, 197, 768]               0\n",
      "        LayerNorm-29             [-1, 197, 768]           1,536\n",
      "           Linear-30            [-1, 197, 3072]       2,362,368\n",
      "             GELU-31            [-1, 197, 3072]               0\n",
      "          Dropout-32            [-1, 197, 3072]               0\n",
      "           Linear-33             [-1, 197, 768]       2,360,064\n",
      "          Dropout-34             [-1, 197, 768]               0\n",
      "      ResidualAdd-35             [-1, 197, 768]               0\n",
      "        LayerNorm-36             [-1, 197, 768]           1,536\n",
      "           Linear-37             [-1, 197, 768]         590,592\n",
      "           Linear-38             [-1, 197, 768]         590,592\n",
      "           Linear-39             [-1, 197, 768]         590,592\n",
      "          Dropout-40          [-1, 8, 197, 197]               0\n",
      "           Linear-41             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-42             [-1, 197, 768]               0\n",
      "          Dropout-43             [-1, 197, 768]               0\n",
      "      ResidualAdd-44             [-1, 197, 768]               0\n",
      "        LayerNorm-45             [-1, 197, 768]           1,536\n",
      "           Linear-46            [-1, 197, 3072]       2,362,368\n",
      "             GELU-47            [-1, 197, 3072]               0\n",
      "          Dropout-48            [-1, 197, 3072]               0\n",
      "           Linear-49             [-1, 197, 768]       2,360,064\n",
      "          Dropout-50             [-1, 197, 768]               0\n",
      "      ResidualAdd-51             [-1, 197, 768]               0\n",
      "        LayerNorm-52             [-1, 197, 768]           1,536\n",
      "           Linear-53             [-1, 197, 768]         590,592\n",
      "           Linear-54             [-1, 197, 768]         590,592\n",
      "           Linear-55             [-1, 197, 768]         590,592\n",
      "          Dropout-56          [-1, 8, 197, 197]               0\n",
      "           Linear-57             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-58             [-1, 197, 768]               0\n",
      "          Dropout-59             [-1, 197, 768]               0\n",
      "      ResidualAdd-60             [-1, 197, 768]               0\n",
      "        LayerNorm-61             [-1, 197, 768]           1,536\n",
      "           Linear-62            [-1, 197, 3072]       2,362,368\n",
      "             GELU-63            [-1, 197, 3072]               0\n",
      "          Dropout-64            [-1, 197, 3072]               0\n",
      "           Linear-65             [-1, 197, 768]       2,360,064\n",
      "          Dropout-66             [-1, 197, 768]               0\n",
      "      ResidualAdd-67             [-1, 197, 768]               0\n",
      "        LayerNorm-68             [-1, 197, 768]           1,536\n",
      "           Linear-69             [-1, 197, 768]         590,592\n",
      "           Linear-70             [-1, 197, 768]         590,592\n",
      "           Linear-71             [-1, 197, 768]         590,592\n",
      "          Dropout-72          [-1, 8, 197, 197]               0\n",
      "           Linear-73             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-74             [-1, 197, 768]               0\n",
      "          Dropout-75             [-1, 197, 768]               0\n",
      "      ResidualAdd-76             [-1, 197, 768]               0\n",
      "        LayerNorm-77             [-1, 197, 768]           1,536\n",
      "           Linear-78            [-1, 197, 3072]       2,362,368\n",
      "             GELU-79            [-1, 197, 3072]               0\n",
      "          Dropout-80            [-1, 197, 3072]               0\n",
      "           Linear-81             [-1, 197, 768]       2,360,064\n",
      "          Dropout-82             [-1, 197, 768]               0\n",
      "      ResidualAdd-83             [-1, 197, 768]               0\n",
      "        LayerNorm-84             [-1, 197, 768]           1,536\n",
      "           Linear-85             [-1, 197, 768]         590,592\n",
      "           Linear-86             [-1, 197, 768]         590,592\n",
      "           Linear-87             [-1, 197, 768]         590,592\n",
      "          Dropout-88          [-1, 8, 197, 197]               0\n",
      "           Linear-89             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-90             [-1, 197, 768]               0\n",
      "          Dropout-91             [-1, 197, 768]               0\n",
      "      ResidualAdd-92             [-1, 197, 768]               0\n",
      "        LayerNorm-93             [-1, 197, 768]           1,536\n",
      "           Linear-94            [-1, 197, 3072]       2,362,368\n",
      "             GELU-95            [-1, 197, 3072]               0\n",
      "          Dropout-96            [-1, 197, 3072]               0\n",
      "           Linear-97             [-1, 197, 768]       2,360,064\n",
      "          Dropout-98             [-1, 197, 768]               0\n",
      "      ResidualAdd-99             [-1, 197, 768]               0\n",
      "       LayerNorm-100             [-1, 197, 768]           1,536\n",
      "          Linear-101             [-1, 197, 768]         590,592\n",
      "          Linear-102             [-1, 197, 768]         590,592\n",
      "          Linear-103             [-1, 197, 768]         590,592\n",
      "         Dropout-104          [-1, 8, 197, 197]               0\n",
      "          Linear-105             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-106             [-1, 197, 768]               0\n",
      "         Dropout-107             [-1, 197, 768]               0\n",
      "     ResidualAdd-108             [-1, 197, 768]               0\n",
      "       LayerNorm-109             [-1, 197, 768]           1,536\n",
      "          Linear-110            [-1, 197, 3072]       2,362,368\n",
      "            GELU-111            [-1, 197, 3072]               0\n",
      "         Dropout-112            [-1, 197, 3072]               0\n",
      "          Linear-113             [-1, 197, 768]       2,360,064\n",
      "         Dropout-114             [-1, 197, 768]               0\n",
      "     ResidualAdd-115             [-1, 197, 768]               0\n",
      "       LayerNorm-116             [-1, 197, 768]           1,536\n",
      "          Linear-117             [-1, 197, 768]         590,592\n",
      "          Linear-118             [-1, 197, 768]         590,592\n",
      "          Linear-119             [-1, 197, 768]         590,592\n",
      "         Dropout-120          [-1, 8, 197, 197]               0\n",
      "          Linear-121             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-122             [-1, 197, 768]               0\n",
      "         Dropout-123             [-1, 197, 768]               0\n",
      "     ResidualAdd-124             [-1, 197, 768]               0\n",
      "       LayerNorm-125             [-1, 197, 768]           1,536\n",
      "          Linear-126            [-1, 197, 3072]       2,362,368\n",
      "            GELU-127            [-1, 197, 3072]               0\n",
      "         Dropout-128            [-1, 197, 3072]               0\n",
      "          Linear-129             [-1, 197, 768]       2,360,064\n",
      "         Dropout-130             [-1, 197, 768]               0\n",
      "     ResidualAdd-131             [-1, 197, 768]               0\n",
      "       LayerNorm-132             [-1, 197, 768]           1,536\n",
      "          Linear-133             [-1, 197, 768]         590,592\n",
      "          Linear-134             [-1, 197, 768]         590,592\n",
      "          Linear-135             [-1, 197, 768]         590,592\n",
      "         Dropout-136          [-1, 8, 197, 197]               0\n",
      "          Linear-137             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-138             [-1, 197, 768]               0\n",
      "         Dropout-139             [-1, 197, 768]               0\n",
      "     ResidualAdd-140             [-1, 197, 768]               0\n",
      "       LayerNorm-141             [-1, 197, 768]           1,536\n",
      "          Linear-142            [-1, 197, 3072]       2,362,368\n",
      "            GELU-143            [-1, 197, 3072]               0\n",
      "         Dropout-144            [-1, 197, 3072]               0\n",
      "          Linear-145             [-1, 197, 768]       2,360,064\n",
      "         Dropout-146             [-1, 197, 768]               0\n",
      "     ResidualAdd-147             [-1, 197, 768]               0\n",
      "       LayerNorm-148             [-1, 197, 768]           1,536\n",
      "          Linear-149             [-1, 197, 768]         590,592\n",
      "          Linear-150             [-1, 197, 768]         590,592\n",
      "          Linear-151             [-1, 197, 768]         590,592\n",
      "         Dropout-152          [-1, 8, 197, 197]               0\n",
      "          Linear-153             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-154             [-1, 197, 768]               0\n",
      "         Dropout-155             [-1, 197, 768]               0\n",
      "     ResidualAdd-156             [-1, 197, 768]               0\n",
      "       LayerNorm-157             [-1, 197, 768]           1,536\n",
      "          Linear-158            [-1, 197, 3072]       2,362,368\n",
      "            GELU-159            [-1, 197, 3072]               0\n",
      "         Dropout-160            [-1, 197, 3072]               0\n",
      "          Linear-161             [-1, 197, 768]       2,360,064\n",
      "         Dropout-162             [-1, 197, 768]               0\n",
      "     ResidualAdd-163             [-1, 197, 768]               0\n",
      "       LayerNorm-164             [-1, 197, 768]           1,536\n",
      "          Linear-165             [-1, 197, 768]         590,592\n",
      "          Linear-166             [-1, 197, 768]         590,592\n",
      "          Linear-167             [-1, 197, 768]         590,592\n",
      "         Dropout-168          [-1, 8, 197, 197]               0\n",
      "          Linear-169             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-170             [-1, 197, 768]               0\n",
      "         Dropout-171             [-1, 197, 768]               0\n",
      "     ResidualAdd-172             [-1, 197, 768]               0\n",
      "       LayerNorm-173             [-1, 197, 768]           1,536\n",
      "          Linear-174            [-1, 197, 3072]       2,362,368\n",
      "            GELU-175            [-1, 197, 3072]               0\n",
      "         Dropout-176            [-1, 197, 3072]               0\n",
      "          Linear-177             [-1, 197, 768]       2,360,064\n",
      "         Dropout-178             [-1, 197, 768]               0\n",
      "     ResidualAdd-179             [-1, 197, 768]               0\n",
      "       LayerNorm-180             [-1, 197, 768]           1,536\n",
      "          Linear-181             [-1, 197, 768]         590,592\n",
      "          Linear-182             [-1, 197, 768]         590,592\n",
      "          Linear-183             [-1, 197, 768]         590,592\n",
      "         Dropout-184          [-1, 8, 197, 197]               0\n",
      "          Linear-185             [-1, 197, 768]         590,592\n",
      "MultiHeadAttention-186             [-1, 197, 768]               0\n",
      "         Dropout-187             [-1, 197, 768]               0\n",
      "     ResidualAdd-188             [-1, 197, 768]               0\n",
      "       LayerNorm-189             [-1, 197, 768]           1,536\n",
      "          Linear-190            [-1, 197, 3072]       2,362,368\n",
      "            GELU-191            [-1, 197, 3072]               0\n",
      "         Dropout-192            [-1, 197, 3072]               0\n",
      "          Linear-193             [-1, 197, 768]       2,360,064\n",
      "         Dropout-194             [-1, 197, 768]               0\n",
      "     ResidualAdd-195             [-1, 197, 768]               0\n",
      "          Reduce-196                  [-1, 768]               0\n",
      "       LayerNorm-197                  [-1, 768]           1,536\n",
      "          Linear-198                 [-1, 1000]         769,000\n",
      "================================================================\n",
      "Total params: 86,415,592\n",
      "Trainable params: 86,415,592\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 364.33\n",
      "Params size (MB): 329.65\n",
      "Estimated Total Size (MB): 694.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ViT().to(device)\n",
    "summary(model, (3,224,224), device=device.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_batch(output, target):\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects\n",
    "\n",
    "\n",
    "# calculate the loss per mini-batch\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss_b = loss_func(output, target)\n",
    "    metric_b = metric_batch(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss_b.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    return loss_b.item(), metric_b\n",
    "\n",
    "\n",
    "# calculate the loss per epochs\n",
    "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb)\n",
    "\n",
    "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "\n",
    "        if sanity_check is True:\n",
    "            break\n",
    "\n",
    "    loss = running_loss / len_data\n",
    "    metric = running_metric / len_data\n",
    "    return loss, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(model, params):\n",
    "    num_epochs=params['num_epochs']\n",
    "    loss_func=params['loss_func']\n",
    "    opt=params['optimizer']\n",
    "    train_dl=params['train_dl']\n",
    "    val_dl=params['val_dl']\n",
    "    sanity_check=params['sanity_check']\n",
    "    lr_scheduler=params['lr_scheduler']\n",
    "    path2weights=params['path2weights']\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), path2weights)\n",
    "            print('Copied best model weights!')\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "        if current_lr != get_lr(opt):\n",
    "            print('Loading best model weights!')\n",
    "            model.load_state_dict(best_model_wts)\n",
    "\n",
    "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train = {\n",
    "    'num_epochs':10,\n",
    "    'optimizer':opt,\n",
    "    'loss_func':loss_func,\n",
    "    'train_dl':train_dl,\n",
    "    'val_dl':val_dl,\n",
    "    'sanity_check':False,\n",
    "    'lr_scheduler':lr_scheduler,\n",
    "    'path2weights':'./models/weights.pt',\n",
    "}\n",
    "\n",
    "# check the directory to save weights.pt\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSerror:\n",
    "        print('Error')\n",
    "createFolder('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9, current lr= 0.01\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 6856) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 6856) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-40a68c4f9fe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-df9a5f6ae678>\u001b[0m in \u001b[0;36mtrain_val\u001b[0;34m(model, params)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanity_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mloss_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mmetric_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-f2d54ec13ff1>\u001b[0m in \u001b[0;36mloss_epoch\u001b[0;34m(model, loss_func, dataset_dl, sanity_check, opt)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlen_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 6856) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = params_train['num_epochs']\n",
    "\n",
    "# Plot train-val loss\n",
    "plt.title('Train-Val Loss')\n",
    "plt.plot(range(1, num_epochs+1), loss_hist['train'], label='train')\n",
    "plt.plot(range(1, num_epochs+1), loss_hist['val'], label='val')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot train-val accuracy\n",
    "plt.title('Train-Val Accuracy')\n",
    "plt.plot(range(1, num_epochs+1), metric_hist['train'], label='train')\n",
    "plt.plot(range(1, num_epochs+1), metric_hist['val'], label='val')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Training Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
